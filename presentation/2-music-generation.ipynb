{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Input, GRU, Flatten, MaxPool2D, MaxPool1D\n",
    "from tensorflow.keras.layers import PReLU, Dropout, Lambda, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from scipy.signal import stft\n",
    "\n",
    "from music_generator.prefabs.random_walk_track import generate_dataset\n",
    "from music_generator.signalproc.signalproc import SamplingInfo\n",
    "from music_generator.music.notes import Note\n",
    "from music_generator.music.timing import Tempo, Signature\n",
    "from music_generator.music.scales import GenericScale\n",
    "from music_generator.music.timing import Duration\n",
    "from music_generator.music.chords import ChordInScaleDefinition\n",
    "# from music_generator.analysis.play import play_mono_as_stereo, play_array\n",
    "from music_generator.signalproc.signalproc import mix_at\n",
    "from music_generator.analysis import preprocessing\n",
    "\n",
    "from music_generator.music import scales\n",
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "\n",
    "from scipy.io.wavfile import read\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpm = 120\n",
    "sr = 44100\n",
    "sampling_info = SamplingInfo(sr)\n",
    "demo_instr = make_lead_instrument(sampling_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A very small bit of music theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/piano.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labels of the notes are (in sharp, #, notation):\n",
    "\n",
    "```\n",
    "  C#   D#        F#   G#   A#\n",
    "C    D    E    F    G    A    B ...\n",
    "```\n",
    "\n",
    "Labels of the notes are (in flat, $\\flat$, notation):\n",
    "\n",
    "```\n",
    "  Db   Eb        Gb   Ab   Bb\n",
    "C    D    E    F    G    A    B ...\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The A in the 4th octave is typically tuned at 440 Hz\n",
    "\n",
    "* A half step is the smallest increment you can make\n",
    "* After twelve half-steps you're back to the same note, but it sounds exactly twice as high\n",
    "* In standard piano tuning, the frequency is multiplied by ${}^{12}\\sqrt{2} \\approx 1.059$\n",
    "\n",
    "Frequency of note is implemented as:\n",
    "\n",
    "$$f = f_{\\mathrm{A4}}\\bigg( {}^{12}\\sqrt{2} \\bigg)^ N $$\n",
    "\n",
    "where $N$ is the number of steps needed (can be negative) to move from A4 to the desired note.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a4 = Note('A', 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a4.frequency()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"A5: {Note('A', 5).frequency()}\")\n",
    "print(f\"C3: {Note('C', 3).frequency()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(demo_instr.generate_note(Note('D', 3)), rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A scale is a selection of notes that fit well together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from music_generator.music.scales import minor_scale, major_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = major_scale('D')\n",
    "scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes = scale.generate(3, 5)\n",
    "notes.append(Note('D', 5))\n",
    "notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_notes = [demo_instr.generate_note(n, Duration(0.5), velocity=0.5) for n in notes] \n",
    "Audio(np.array(generated_notes).reshape(-1), rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For every note in the scale a fitting chord can be calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_ = notes + [notes[-1]]*2\n",
    "auto_chords = ChordInScaleDefinition(scale=scale)\n",
    "chords = [auto_chords.generate_chord(n) for n in notes_]\n",
    "Audio(np.array([demo_instr.generate_chord(c, time=Duration(0.1)) \n",
    "                for c in np.repeat(chords, 4)]).reshape(-1), rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic improvisation using random walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_measures = 8\n",
    "tempo = Tempo(120)\n",
    "signature = Signature(4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from music_generator.music.score import Measure, Tempo, Track, Score, Signature\n",
    "from music_generator.synthesizer.instrument import Instrument\n",
    "from music_generator.synthesizer.oscillators import FilteredOscillator\n",
    "from music_generator.synthesizer.oscillators import SquareOscillator, LinearAdsrGenerator, FilteredOscillator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First make a chord track with a soft sounding synthesizer\n",
    "\n",
    "This chord progression is the most used in pop-music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chords_instr = make_accomp_instrument(sampling_info)\n",
    "\n",
    "from music_generator.prefabs.random_walk_track import generate_chord_track\n",
    "chord_track = generate_chord_track(scale, tempo, signature, n_measures)\n",
    "chord_audio = chords_instr.generate_track(chord_track)\n",
    "\n",
    "Audio(chord_audio, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Perform a random walk through the scale\n",
    "* Tune the step (interval) probabilities a bit, so that it sounds ok.\n",
    "    * Small intervals have higher probabilities than big intervals\n",
    "* In order to prevent very low or high sounding melodies: mirror step whenever random walk steps outside boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes = scale.generate(4, 6)\n",
    "\n",
    "# Generate 16th notes\n",
    "n_notes = int(n_measures * 16)\n",
    "\n",
    "p = [0.0005, 0.01, 0.1, 0.3, 0.0, 0.3, 0.1, 0.01, 0.0005]\n",
    "p = p / np.sum(p)\n",
    "\n",
    "steps = np.random.choice([-4, -3, -2, -1, 0, 1, 2, 3, 4],\n",
    "                         n_notes - 1, p=p)\n",
    "\n",
    "from music_generator.basic.utils import elastic_bounded_random_walk\n",
    "rw = elastic_bounded_random_walk(steps, np.random.randint(0, len(notes)), 0, len(notes))\n",
    "\n",
    "plt.plot(rw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can turn the random walk into an array of notes by indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(notes)[rw.astype(int)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can feed this to a synthesizer and generate some music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_measure = Measure(tempo, signature)\n",
    "for i_note, note in enumerate(np.array(notes)[rw.astype(int)]):\n",
    "    lead_measure.add_note(note, i_note/4, 1/4)\n",
    "\n",
    "lead_trk = Track([lead_measure])\n",
    "\n",
    "lead_instrument = make_lead_instrument(sampling_info)\n",
    "lead_audio = lead_instrument.generate_track(lead_trk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mix it together with the chords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mix = chord_audio.copy()\n",
    "mix = mix_at(0.5*mix, lead_audio, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(mix, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
