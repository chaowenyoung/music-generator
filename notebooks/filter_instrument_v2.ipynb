{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Regeneration of lead synth from combined signal\"\"\"\n",
    "from tensorflow.keras.layers import Dense, Dropout, PReLU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from music_generator.basic.random import generate_dataset\n",
    "from music_generator.basic.signalproc import SamplingInfo\n",
    "from music_generator.musical.timing import Tempo\n",
    "from music_generator.musical.scales import GenericScale\n",
    "from music_generator.basic.signalproc import mix_at\n",
    "from music_generator.analysis import preprocessing\n",
    "\n",
    "from music_generator.musical import scales\n",
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio\n",
    "from scipy.io.wavfile import read\n",
    "from music_generator.analysis import regen_models\n",
    "from scipy.io import wavfile\n",
    "from music_generator.analysis import jamdataset\n",
    "import tensorflow as tf\n",
    "\n",
    "from music_generator.analysis import regen_models\n",
    "import importlib\n",
    "\n",
    "from tensorflow.keras.layers import Input, GRU, PReLU, Dropout, Dense, Reshape, Conv1D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "\n",
    "from tensorflow.keras.callbacks import TensorBoard, ReduceLROnPlateau, ModelCheckpoint\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = 44100\n",
    "sampling_info = SamplingInfo(sr)\n",
    "fragment_length = 4096\n",
    "batch_size = 32\n",
    "sr = sampling_info.sample_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from music_generator.analysis.data.filtering import generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = generate.generate_synthetic_data(batch_size, fragment_length, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_fft_model(batch_size, fragment_length):\n",
    "    \n",
    "    inp = Input(batch_shape=[batch_size, fragment_length])\n",
    "    hidden = inp\n",
    "    \n",
    "    n_fft_steps = 4\n",
    "    n_channels_fft = fragment_length // n_fft_steps\n",
    "    \n",
    "    hidden = Reshape([n_fft_steps, n_channels_fft])(hidden)\n",
    "    \n",
    "    hidden = tf.signal.fft(tf.cast(hidden, tf.complex64))\n",
    "    hidden_abs = tf.math.abs(hidden)\n",
    "    hidden_ang = tf.math.angle(hidden)\n",
    "    \n",
    "    hidden_abs = GRU(2048, return_sequences=True)(hidden_abs)\n",
    "    hidden_abs = GRU(1024, return_sequences=True)(hidden_abs)    \n",
    "    hidden_abs = Dense(n_channels_fft, activation=\"relu\")(hidden_abs)\n",
    "    hidden_abs = Dense(n_channels_fft, activation=\"relu\")(hidden_abs)    \n",
    "\n",
    "    hidden = tf.complex(hidden_abs * tf.math.cos(hidden_ang), hidden_abs * tf.math.sin(hidden_ang))\n",
    "    \n",
    "    # hidden = Dense(n_channels_fft)\n",
    "    \n",
    "    hidden = tf.signal.ifft(hidden)\n",
    "    hidden = tf.cast(hidden, tf.float32)\n",
    "    hidden = Reshape([fragment_length])(hidden)\n",
    "    \n",
    "    out = hidden\n",
    "    \n",
    "    return Model(inp, out)\n",
    "\n",
    "def fft_loss(y_target, y_predicted):\n",
    "    y_target_complex = tf.cast(y_target, dtype=tf.complex64)\n",
    "    y_predicted_complex = tf.cast(y_predicted, dtype=tf.complex64)\n",
    "\n",
    "    loss = tf.square(tf.abs(tf.signal.fft(y_target_complex))[100:] -\n",
    "                     tf.abs(tf.signal.fft(y_predicted_complex))[100:])\n",
    "    return loss\n",
    "\n",
    "model = build_fft_model(batch_size, fragment_length)\n",
    "model.summary()\n",
    "model.compile(RMSprop(1e-3), loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = []\n",
    "\n",
    "model.fit(x_train, y_train, validation_data=[x_test, y_test], callbacks=callbacks, epochs=25, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_test_1 = model.predict(x_test, verbose=1).reshape(-1)\n",
    "output_train_1 = model.predict(x_train, verbose=1).reshape(-1)\n",
    "Audio(output_test_1[:1000000], rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_LENGTH = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_fix_model(window_length):\n",
    "    \n",
    "    inp = Input(shape=[window_length])\n",
    "    hidden = inp\n",
    "    \n",
    "    hidden = Reshape([window_length, 1])(hidden)\n",
    "    \n",
    "    hidden = Conv1D(filters=25, kernel_size=15, padding=\"same\")(hidden)\n",
    "    \n",
    "    hidden = Dense(1)(hidden)\n",
    "    hidden = Reshape([window_length])(hidden)\n",
    "    \n",
    "    out = hidden\n",
    "    \n",
    "    model = Model(inp, out)\n",
    "    model.compile(\"adam\", \"mse\")\n",
    "    return model\n",
    "    \n",
    "fix_model = build_fix_model(WINDOW_LENGTH)\n",
    "fix_model.summary()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_fix_input = output_train_1.reshape(-1).reshape(-1, WINDOW_LENGTH)\n",
    "y_train_fix_target = y_train.reshape(-1).reshape(-1, WINDOW_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_model.fit(y_train_fix_input, y_train_fix_target, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_fixed = fix_model.predict(output_test_1.reshape(-1).reshape(-1, WINDOW_LENGTH)).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(output_fixed[:1000000], rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(output_test_1[:1000000], rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
